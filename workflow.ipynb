{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18858,"sourceType":"datasetVersion","datasetId":13996}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ“Š Telco Customer Churn Prediction\n\n## ðŸ”Ž Project Overview\nThis notebook builds a **customer churn prediction system** for a telecom company using the [Telco Customer Churn dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn).  \n\nChurn (Yes/No) represents whether a customer **left the company**. Predicting churn is crucial because acquiring new customers is often more expensive than retaining existing ones.  \n\nThe project follows a structured data science workflow:\n\n---\n\n## ðŸ“‹ Workflow\n1. **Initial Data Assessment**\n   - Data types, missing values, and inconsistencies\n   - Target variable analysis (churn rate and class imbalance)\n   - Categorization of features into demographics, services, and financials  \n\n2. **Exploratory Data Analysis (EDA)**\n   - Outlier detection using IQR and boxplots\n   - Univariate, bivariate, and multivariate analysis\n   - Churn patterns across customer segments  \n\n3. **Feature Engineering**\n   - Derived features such as:\n     - `TenureCategory` (New / Established / Loyal)\n     - `ServiceCount` (number of services subscribed)\n     - `BundleUser` (subscribed to both Internet + Phone)\n     - `ChargeCategory` (low / medium / high spenders)\n   - Encoding categorical features  \n\n4. **Preprocessing & Transformations**\n   - Handling missing values\n   - Scaling numeric features\n   - Log and power transformations for skewed variables\n   - One-hot encoding categorical features  \n\n5. **Modeling**\n   - Baseline: Logistic Regression, Decision Tree\n   - Ensemble methods: Random Forest, XGBoost, CatBoost\n   - **Pipeline integration** with preprocessing  \n\n6. **Model Evaluation**\n   - Metrics for imbalanced data: Precision, Recall, F1-score, ROC-AUC\n   - Comparison of models\n   - Business interpretation of evaluation metrics  \n\n7. **Business Insights & Recommendations**\n   - High-risk customer profiles\n   - Retention strategies (contract incentives, discounts, bundled services)\n   - Estimated revenue impact and ROI from retention  \n\n---\n\n## ðŸŽ¯ Learning Outcomes\n- Ability to handle **class imbalance** in real-world datasets\n- Building robust **data and model pipelines**\n- Experience with **ensemble methods** (bagging & boosting)  \n- Advanced **EDA and feature engineering** for actionable insights  \n- Translation of machine learning results into **business value**  \n\n---\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_validate\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer, FunctionTransformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\n\nimport warnings\n\n# Ignore all warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.287883Z","iopub.execute_input":"2025-08-28T21:20:56.288254Z","iopub.status.idle":"2025-08-28T21:20:56.305370Z","shell.execute_reply.started":"2025-08-28T21:20:56.288229Z","shell.execute_reply":"2025-08-28T21:20:56.303963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Load Dataset**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.306952Z","iopub.execute_input":"2025-08-28T21:20:56.307317Z","iopub.status.idle":"2025-08-28T21:20:56.372331Z","shell.execute_reply.started":"2025-08-28T21:20:56.307287Z","shell.execute_reply":"2025-08-28T21:20:56.371364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.373213Z","iopub.execute_input":"2025-08-28T21:20:56.373463Z","iopub.status.idle":"2025-08-28T21:20:56.397374Z","shell.execute_reply.started":"2025-08-28T21:20:56.373443Z","shell.execute_reply":"2025-08-28T21:20:56.396222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.399304Z","iopub.execute_input":"2025-08-28T21:20:56.399599Z","iopub.status.idle":"2025-08-28T21:20:56.431693Z","shell.execute_reply.started":"2025-08-28T21:20:56.399567Z","shell.execute_reply":"2025-08-28T21:20:56.430921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe(include = \"all\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.432484Z","iopub.execute_input":"2025-08-28T21:20:56.432743Z","iopub.status.idle":"2025-08-28T21:20:56.509219Z","shell.execute_reply.started":"2025-08-28T21:20:56.432717Z","shell.execute_reply":"2025-08-28T21:20:56.507742Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.510563Z","iopub.execute_input":"2025-08-28T21:20:56.510949Z","iopub.status.idle":"2025-08-28T21:20:56.526300Z","shell.execute_reply.started":"2025-08-28T21:20:56.510919Z","shell.execute_reply":"2025-08-28T21:20:56.525421Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are 7043 customers in the dataset and there are no missing values","metadata":{}},{"cell_type":"markdown","source":"# **EDA**","metadata":{}},{"cell_type":"code","source":"categorical_features = df.select_dtypes(include=['object']).columns.tolist()\nfor i in categorical_features:\n    print(i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.527216Z","iopub.execute_input":"2025-08-28T21:20:56.527463Z","iopub.status.idle":"2025-08-28T21:20:56.547483Z","shell.execute_reply.started":"2025-08-28T21:20:56.527443Z","shell.execute_reply":"2025-08-28T21:20:56.546080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify numerical features\nnumerical_features = df.select_dtypes(include=['int64','float64']).columns.tolist()\nfor i in numerical_features:\n    print(i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.548444Z","iopub.execute_input":"2025-08-28T21:20:56.548754Z","iopub.status.idle":"2025-08-28T21:20:56.568759Z","shell.execute_reply.started":"2025-08-28T21:20:56.548732Z","shell.execute_reply":"2025-08-28T21:20:56.567509Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Most of the featues in the dataset are categorical","metadata":{}},{"cell_type":"code","source":"for cat in categorical_features:\n    print(cat)\n    print(df[cat].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.571711Z","iopub.execute_input":"2025-08-28T21:20:56.572456Z","iopub.status.idle":"2025-08-28T21:20:56.610451Z","shell.execute_reply.started":"2025-08-28T21:20:56.572430Z","shell.execute_reply":"2025-08-28T21:20:56.609209Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We do not need the customer id column for EDA","metadata":{}},{"cell_type":"code","source":"categorical_features.remove(\"customerID\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.611455Z","iopub.execute_input":"2025-08-28T21:20:56.611746Z","iopub.status.idle":"2025-08-28T21:20:56.618985Z","shell.execute_reply.started":"2025-08-28T21:20:56.611723Z","shell.execute_reply":"2025-08-28T21:20:56.617752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for num in numerical_features:\n    print(num)\n    print(df[num].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.619674Z","iopub.execute_input":"2025-08-28T21:20:56.619966Z","iopub.status.idle":"2025-08-28T21:20:56.641855Z","shell.execute_reply.started":"2025-08-28T21:20:56.619944Z","shell.execute_reply":"2025-08-28T21:20:56.640406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Have to treat SeniorCitizen as a categorical feature\n* Have to treat total charges as a numerical feature","metadata":{}},{"cell_type":"code","source":"numerical_features.remove(\"SeniorCitizen\")  # treat this as categorical\ncategorical_features.append(\"SeniorCitizen\")\n\ncategorical_features.remove(\"TotalCharges\") #treat this as numerical\nnumerical_features.append(\"TotalCharges\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.643009Z","iopub.execute_input":"2025-08-28T21:20:56.643324Z","iopub.status.idle":"2025-08-28T21:20:56.658551Z","shell.execute_reply.started":"2025-08-28T21:20:56.643301Z","shell.execute_reply":"2025-08-28T21:20:56.657024Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* TotalCharges has to be numerical","metadata":{}},{"cell_type":"code","source":"# Convert TotalCharges to numeric, forcing errors to NaN\ndf[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n\n# Check how many became NaN (were blanks)\nprint(\"Missing values in TotalCharges:\", df[\"TotalCharges\"].isna().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.659456Z","iopub.execute_input":"2025-08-28T21:20:56.659740Z","iopub.status.idle":"2025-08-28T21:20:56.684668Z","shell.execute_reply.started":"2025-08-28T21:20:56.659718Z","shell.execute_reply":"2025-08-28T21:20:56.683686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find rows where TotalCharges is NaN\nmissing_total = df[df[\"TotalCharges\"].isna()]\n\n# Show how many and their tenure values\nprint(missing_total[\"tenure\"].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.685671Z","iopub.execute_input":"2025-08-28T21:20:56.685963Z","iopub.status.idle":"2025-08-28T21:20:56.710568Z","shell.execute_reply.started":"2025-08-28T21:20:56.685942Z","shell.execute_reply":"2025-08-28T21:20:56.709515Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"These are brand new customers and have a 0 totalcharge. We will impute the 0 for Total Charges","metadata":{}},{"cell_type":"code","source":"# Impute with 0 (new customers with no charges yet)\ndf[\"TotalCharges\"].fillna(0, inplace=True)\n\n# Verify\nprint(df[\"TotalCharges\"].dtype)\nprint(df.loc[df[\"tenure\"] == 0, [\"tenure\", \"TotalCharges\"]].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.712799Z","iopub.execute_input":"2025-08-28T21:20:56.713104Z","iopub.status.idle":"2025-08-28T21:20:56.737659Z","shell.execute_reply.started":"2025-08-28T21:20:56.713076Z","shell.execute_reply":"2025-08-28T21:20:56.735699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.788999Z","iopub.execute_input":"2025-08-28T21:20:56.789308Z","iopub.status.idle":"2025-08-28T21:20:56.809024Z","shell.execute_reply.started":"2025-08-28T21:20:56.789287Z","shell.execute_reply":"2025-08-28T21:20:56.807300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.811261Z","iopub.execute_input":"2025-08-28T21:20:56.811642Z","iopub.status.idle":"2025-08-28T21:20:56.833076Z","shell.execute_reply.started":"2025-08-28T21:20:56.811616Z","shell.execute_reply":"2025-08-28T21:20:56.832230Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.883932Z","iopub.execute_input":"2025-08-28T21:20:56.884351Z","iopub.status.idle":"2025-08-28T21:20:56.891088Z","shell.execute_reply.started":"2025-08-28T21:20:56.884326Z","shell.execute_reply":"2025-08-28T21:20:56.890132Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ðŸ‘¤ Demographic Features\n- **gender** â€“ Whether the customer is male or female  \n- **SeniorCitizen** â€“ Indicates if the customer is a senior citizen (1 = Yes, 0 = No)  \n- **Partner** â€“ Whether the customer has a partner  \n- **Dependents** â€“ Whether the customer has dependents  \n\n### ðŸ”§ Behavioral / Services Features\n- **PhoneService** â€“ Whether the customer has phone service  \n- **MultipleLines** â€“ Whether the customer has multiple lines  \n- **InternetService** â€“ Type of internet service (DSL, Fiber optic, None)  \n- **OnlineSecurity** â€“ Whether the customer has online security service  \n- **OnlineBackup** â€“ Whether the customer has online backup service  \n- **DeviceProtection** â€“ Whether the customer has device protection service  \n- **TechSupport** â€“ Whether the customer has tech support service  \n- **StreamingTV** â€“ Whether the customer has streaming TV service  \n- **StreamingMovies** â€“ Whether the customer has streaming movies service  \n- **Contract** â€“ Type of contract (Month-to-month, One year, Two year)  \n- **PaperlessBilling** â€“ Whether the customer uses paperless billing  \n\n### ðŸ’° Financial Features\n- **MonthlyCharges** â€“ Amount charged to the customer monthly  \n- **TotalCharges** â€“ Total amount charged to the customer during their tenure  \n- **PaymentMethod** â€“ Payment method used by the customer  \n\n### ðŸŽ¯ Target Variable\n- **Churn** â€“ Indicates whether the customer left the company (Yes = churned, No = retained)\n","metadata":{}},{"cell_type":"markdown","source":"# **Churn distribution**","metadata":{}},{"cell_type":"code","source":"# Target distribution\nsns.countplot(data=df, x=\"Churn\")\nplt.title(\"Churn Distribution\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:56.905917Z","iopub.execute_input":"2025-08-28T21:20:56.906510Z","iopub.status.idle":"2025-08-28T21:20:57.060297Z","shell.execute_reply.started":"2025-08-28T21:20:56.906484Z","shell.execute_reply":"2025-08-28T21:20:57.059300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"churn_rate = df[\"Churn\"].value_counts(normalize=True)\nprint(\"Churn Rate:\\n\", churn_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:57.061734Z","iopub.execute_input":"2025-08-28T21:20:57.062043Z","iopub.status.idle":"2025-08-28T21:20:57.069575Z","shell.execute_reply.started":"2025-08-28T21:20:57.062013Z","shell.execute_reply":"2025-08-28T21:20:57.068559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"churn_counts = df['Churn'].value_counts()\nimbalance_ratio = churn_counts['No'] / churn_counts['Yes']\nprint(\"Imbalance Ratio (No:Yes) =\", imbalance_ratio)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:57.070302Z","iopub.execute_input":"2025-08-28T21:20:57.070534Z","iopub.status.idle":"2025-08-28T21:20:57.089005Z","shell.execute_reply.started":"2025-08-28T21:20:57.070516Z","shell.execute_reply":"2025-08-28T21:20:57.088108Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It seems like there is a huge imbalance in the dataset where the number of not churned customers are high than the number of churned customers","metadata":{}},{"cell_type":"markdown","source":"# **Categorical Feature distributions**","metadata":{}},{"cell_type":"code","source":"for col in categorical_features:\n    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n\n    # Left: Distribution of feature\n    sns.countplot(x=col, data=df, ax=axes[0], palette=\"Set2\")\n    axes[0].set_title(f\"Distribution of {col}\")\n    axes[0].tick_params(axis='x', rotation=45)\n\n    # Right: Feature vs Churn\n    churn_dist = pd.crosstab(df[col], df['Churn'], normalize='index') * 100\n    churn_dist.plot(kind='bar', stacked=True, color=['skyblue','salmon'], ax=axes[1])\n    axes[1].set_title(f\"Churn % by {col}\")\n    axes[1].set_ylabel(\"Percentage\")\n    axes[1].legend(title=\"Churn\")\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:20:57.089943Z","iopub.execute_input":"2025-08-28T21:20:57.090371Z","iopub.status.idle":"2025-08-28T21:21:03.693188Z","shell.execute_reply.started":"2025-08-28T21:20:57.090344Z","shell.execute_reply":"2025-08-28T21:21:03.692243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Numerical Feature Distributions**","metadata":{}},{"cell_type":"code","source":"for col in numerical_features:\n    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n\n    # Left: Distribution (histogram)\n    sns.histplot(df[col], bins=30, kde=True, ax=axes[0], color=\"skyblue\")\n    axes[0].set_title(f\"Distribution of {col}\")\n\n    # Right: Boxplot vs Churn\n    sns.boxplot(x=\"Churn\", y=col, data=df, palette=\"Set2\", ax=axes[1])\n    axes[1].set_title(f\"{col} by Churn\")\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:03.695459Z","iopub.execute_input":"2025-08-28T21:21:03.695730Z","iopub.status.idle":"2025-08-28T21:21:05.217866Z","shell.execute_reply.started":"2025-08-28T21:21:03.695709Z","shell.execute_reply":"2025-08-28T21:21:05.216673Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Outlier Detection**","metadata":{}},{"cell_type":"code","source":"for col in numerical_features:\n    plt.figure(figsize=(10,4))\n\n    # Boxplot\n    sns.boxplot(x=df[col], color=\"skyblue\")\n    plt.title(f\"Boxplot of {col}\")\n    plt.show()\n\n    # IQR Calculation\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n\n    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n    print(f\"{col}: {outliers.shape[0]} outliers detected\")\n    print(f\"Lower bound: {lower_bound}, Upper bound: {upper_bound}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:05.218797Z","iopub.execute_input":"2025-08-28T21:21:05.219038Z","iopub.status.idle":"2025-08-28T21:21:05.604440Z","shell.execute_reply.started":"2025-08-28T21:21:05.219018Z","shell.execute_reply":"2025-08-28T21:21:05.603628Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"No outliers detected","metadata":{}},{"cell_type":"markdown","source":"# **Feature Engineering**","metadata":{}},{"cell_type":"markdown","source":"# Tenture_category\n\n* New: 0-1 year\n* Established: 1-4 years\n* Loyal: 4-6 years","metadata":{}},{"cell_type":"code","source":"def tenure_category(tenure):\n    if tenure <= 12: \n        return \"New\"          # 0â€“1 year\n    elif tenure <= 48: \n        return \"Established\"  # 1â€“4 years\n    else: \n        return \"Loyal\"        # 4â€“6 years\n\ndf[\"Tenure_category\"] = df[\"tenure\"].apply(tenure_category)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:05.605307Z","iopub.execute_input":"2025-08-28T21:21:05.605579Z","iopub.status.idle":"2025-08-28T21:21:05.614199Z","shell.execute_reply.started":"2025-08-28T21:21:05.605541Z","shell.execute_reply":"2025-08-28T21:21:05.612876Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Charge_category\n\n* The Charge_category is involved in monthly charges","metadata":{}},{"cell_type":"code","source":"df[\"Charge_category\"] = pd.qcut(df[\"MonthlyCharges\"], q=3, labels=[\"Low\",\"Medium\",\"High\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:05.615241Z","iopub.execute_input":"2025-08-28T21:21:05.615507Z","iopub.status.idle":"2025-08-28T21:21:05.637887Z","shell.execute_reply.started":"2025-08-28T21:21:05.615486Z","shell.execute_reply":"2025-08-28T21:21:05.636947Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Service_count\n\n* Total number of services a customer has","metadata":{}},{"cell_type":"code","source":"service_cols = ['PhoneService','MultipleLines','InternetService',\n                'OnlineSecurity','OnlineBackup','DeviceProtection',\n                'TechSupport','StreamingTV','StreamingMovies']\n\ndf[\"Service_count\"] = (df[service_cols] == \"Yes\").sum(axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:05.639085Z","iopub.execute_input":"2025-08-28T21:21:05.640041Z","iopub.status.idle":"2025-08-28T21:21:05.658497Z","shell.execute_reply.started":"2025-08-28T21:21:05.640006Z","shell.execute_reply":"2025-08-28T21:21:05.657609Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Bundle_user\n\n* Customers with both Internet + Phone","metadata":{}},{"cell_type":"code","source":"# BundleUser: 1 if customer has BOTH InternetService (not 'No') and PhoneService = 'Yes'\ndf[\"Bundle_user\"] = np.where(\n    (df[\"InternetService\"] != \"No\") & (df[\"PhoneService\"] == \"Yes\"), 1, 0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:05.660007Z","iopub.execute_input":"2025-08-28T21:21:05.660307Z","iopub.status.idle":"2025-08-28T21:21:05.678266Z","shell.execute_reply.started":"2025-08-28T21:21:05.660278Z","shell.execute_reply":"2025-08-28T21:21:05.677328Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **EDA after feature engineering**","metadata":{}},{"cell_type":"code","source":"categorical_features.extend([\"Charge_category\", \"Tenure_category\",\"Bundle_user\"])\nnumerical_features.append(\"Service_count\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:05.679230Z","iopub.execute_input":"2025-08-28T21:21:05.679545Z","iopub.status.idle":"2025-08-28T21:21:05.696051Z","shell.execute_reply.started":"2025-08-28T21:21:05.679516Z","shell.execute_reply":"2025-08-28T21:21:05.695127Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Feature distributions**","metadata":{}},{"cell_type":"code","source":"for col in categorical_features:\n    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n\n    # Left: Distribution of feature\n    sns.countplot(x=col, data=df, ax=axes[0], palette=\"Set2\")\n    axes[0].set_title(f\"Distribution of {col}\")\n    axes[0].tick_params(axis='x', rotation=45)\n\n    # Right: Feature vs Churn\n    churn_dist = pd.crosstab(df[col], df['Churn'], normalize='index') * 100\n    churn_dist.plot(kind='bar', stacked=True, color=['skyblue','salmon'], ax=axes[1])\n    axes[1].set_title(f\"Churn % by {col}\")\n    axes[1].set_ylabel(\"Percentage\")\n    axes[1].legend(title=\"Churn\")\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:05.697110Z","iopub.execute_input":"2025-08-28T21:21:05.697414Z","iopub.status.idle":"2025-08-28T21:21:13.523514Z","shell.execute_reply.started":"2025-08-28T21:21:05.697394Z","shell.execute_reply":"2025-08-28T21:21:13.522548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in numerical_features:\n    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n\n    # Left: Distribution (histogram)\n    sns.histplot(df[col], bins=30, kde=True, ax=axes[0], color=\"skyblue\")\n    axes[0].set_title(f\"Distribution of {col}\")\n\n    # Right: Boxplot vs Churn\n    sns.boxplot(x=\"Churn\", y=col, data=df, palette=\"Set2\", ax=axes[1])\n    axes[1].set_title(f\"{col} by Churn\")\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:13.524599Z","iopub.execute_input":"2025-08-28T21:21:13.524850Z","iopub.status.idle":"2025-08-28T21:21:15.515438Z","shell.execute_reply.started":"2025-08-28T21:21:13.524831Z","shell.execute_reply":"2025-08-28T21:21:15.514090Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Transforming Strategy**","metadata":{}},{"cell_type":"markdown","source":"# TotalCharges","metadata":{}},{"cell_type":"code","source":"feature = \"TotalCharges\"\nx = df[feature].copy()\n\n# Transformations\ntransforms = {\n    \"Original\": x,\n    \"Log\": np.log1p(x),\n    \"Sqrt\": np.sqrt(x),\n    \"Cube Root\": np.cbrt(x),\n    \"Reciprocal\": 1/(x+1),  # +1 to avoid division by zero\n    \"Yeo-Johnson\": PowerTransformer(method=\"yeo-johnson\").fit_transform(x.values.reshape(-1,1)).flatten()\n}\n\n# Plot results\nplt.figure(figsize=(12,8))\nfor i, (name, vals) in enumerate(transforms.items(), 1):\n    plt.subplot(3,2,i)\n    sns.histplot(vals, bins=30, kde=True, color=\"skyblue\")\n    plt.title(f\"{feature} - {name}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:15.518693Z","iopub.execute_input":"2025-08-28T21:21:15.518987Z","iopub.status.idle":"2025-08-28T21:21:17.274880Z","shell.execute_reply.started":"2025-08-28T21:21:15.518966Z","shell.execute_reply":"2025-08-28T21:21:17.273940Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Square root is better","metadata":{}},{"cell_type":"markdown","source":"# MonthlyCharges","metadata":{}},{"cell_type":"code","source":"feature = \"MonthlyCharges\"\nx = df[feature].copy()\n\n# Transformations\ntransforms = {\n    \"Original\": x,\n    \"Log\": np.log1p(x),\n    \"Sqrt\": np.sqrt(x),\n    \"Cube Root\": np.cbrt(x),\n    \"Reciprocal\": 1/(x+1),  # +1 to avoid division by zero\n    \"Yeo-Johnson\": PowerTransformer(method=\"yeo-johnson\").fit_transform(x.values.reshape(-1,1)).flatten()\n}\n\n# Plot results\nplt.figure(figsize=(12,8))\nfor i, (name, vals) in enumerate(transforms.items(), 1):\n    plt.subplot(3,2,i)\n    sns.histplot(vals, bins=30, kde=True, color=\"skyblue\")\n    plt.title(f\"{feature} - {name}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:17.275869Z","iopub.execute_input":"2025-08-28T21:21:17.276138Z","iopub.status.idle":"2025-08-28T21:21:19.203272Z","shell.execute_reply.started":"2025-08-28T21:21:17.276117Z","shell.execute_reply":"2025-08-28T21:21:19.201768Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* No need to transform because each graph looks like the same","metadata":{}},{"cell_type":"markdown","source":"# tenture","metadata":{}},{"cell_type":"code","source":"feature = \"tenure\"\nx = df[feature].copy()\n\n# Transformations\ntransforms = {\n    \"Original\": x,\n    \"Log\": np.log1p(x),\n    \"Sqrt\": np.sqrt(x),\n    \"Cube Root\": np.cbrt(x),\n    \"Reciprocal\": 1/(x+1),  # +1 to avoid division by zero\n    \"Yeo-Johnson\": PowerTransformer(method=\"yeo-johnson\").fit_transform(x.values.reshape(-1,1)).flatten()\n}\n\n# Plot results\nplt.figure(figsize=(12,8))\nfor i, (name, vals) in enumerate(transforms.items(), 1):\n    plt.subplot(3,2,i)\n    sns.histplot(vals, bins=30, kde=True, color=\"skyblue\")\n    plt.title(f\"{feature} - {name}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:19.204309Z","iopub.execute_input":"2025-08-28T21:21:19.204641Z","iopub.status.idle":"2025-08-28T21:21:20.932662Z","shell.execute_reply.started":"2025-08-28T21:21:19.204615Z","shell.execute_reply":"2025-08-28T21:21:20.931722Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* No need to transform","metadata":{}},{"cell_type":"code","source":"categorical_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:20.933646Z","iopub.execute_input":"2025-08-28T21:21:20.934078Z","iopub.status.idle":"2025-08-28T21:21:20.941102Z","shell.execute_reply.started":"2025-08-28T21:21:20.934013Z","shell.execute_reply":"2025-08-28T21:21:20.939642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define x and y\nX = df.drop([\"Churn\"], axis = 1)\ny = df[\"Churn\"].map({\n    \"Yes\":1,\n    \"No\":0\n})\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n\n# Keep customerID from test set separately\ncustomer_id = X_test[\"customerID\"].copy()\n\n# Drop customerID from features (train and test)\nX_train = X_train.drop(\"customerID\", axis=1)\nX_test = X_test.drop(\"customerID\", axis=1)\n\n# Check shape\nX_train.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:20.942328Z","iopub.execute_input":"2025-08-28T21:21:20.942686Z","iopub.status.idle":"2025-08-28T21:21:20.976172Z","shell.execute_reply.started":"2025-08-28T21:21:20.942656Z","shell.execute_reply":"2025-08-28T21:21:20.975299Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data Preprocessing Pipeline**","metadata":{}},{"cell_type":"code","source":"# Step 1: Apply sqrt to the selected column\nsqrt_obj = FunctionTransformer(np.sqrt,validate = True)\nsqrt_features = ['TotalCharges']\n\nsqrt_transformer = ColumnTransformer(\n    transformers=[\n        ('sqrt',sqrt_obj,sqrt_features),\n    ],\n    remainder = 'passthrough'\n)\n\n# # Step 2: Scaling & normalization to all numeric columns\nnumeric_pipeline = Pipeline(\n    steps=[\n        ('sqrt_transform',sqrt_transformer),\n        ('scaler',StandardScaler()),\n    ]\n)\n\n# Step 3: Define objects for categorical columns\ncat_features = [col for col in categorical_features if col != \"Churn\"]\nnorminal_encoder = OneHotEncoder(handle_unknown='ignore',sparse_output=False)\n\n# Step 4: Make the entire preprocessing pipeline\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num',numeric_pipeline,numerical_features),\n        ('cat',norminal_encoder,cat_features)\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:20.977105Z","iopub.execute_input":"2025-08-28T21:21:20.977429Z","iopub.status.idle":"2025-08-28T21:21:20.983961Z","shell.execute_reply.started":"2025-08-28T21:21:20.977403Z","shell.execute_reply":"2025-08-28T21:21:20.982971Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Building Pipeline**","metadata":{}},{"cell_type":"code","source":"# Suppose in training set:\nn_positive = sum(y_train == 1)  # churned customers\nn_negative = sum(y_train == 0)  # non-churned customers\n\nscale_pos_weight = n_negative / n_positive\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter = 100,class_weight = 'balanced'),\n    \"Decision Tree\": DecisionTreeClassifier(class_weight = 'balanced'),\n    \"Random Forest\": RandomForestClassifier(n_estimators= 100,class_weight='balanced'),\n    \"XGBoost\": xgb.XGBClassifier(eval_metric='logloss',scale_pos_weight = (n_negative / n_positive)),\n    \"CatBoost\":CatBoostClassifier(verbose=0,auto_class_weights='Balanced')\n}\n\n# Stratified CV\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nresults = {}\n\nfor name, model in models.items():\n    clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)])\n    \n    # --- Cross-validation on training data ---\n    cv_scores = cross_validate(\n        clf, X_train, y_train, cv=cv,\n        scoring=[\"accuracy\", \"roc_auc\"], return_train_score=True\n    )\n    \n    # --- Fit on full training set ---\n    clf.fit(X_train, y_train)\n    \n    # --- Predictions for training and test sets ---\n    y_train_pred = clf.predict(X_train)\n    y_test_pred = clf.predict(X_test)\n    \n    y_train_proba = clf.predict_proba(X_train)[:,1]\n    y_test_proba = clf.predict_proba(X_test)[:,1]\n    \n    # --- Metrics ---\n    train_acc = accuracy_score(y_train, y_train_pred)\n    test_acc = accuracy_score(y_test, y_test_pred)\n    train_auc = roc_auc_score(y_train, y_train_proba)\n    test_auc = roc_auc_score(y_test, y_test_proba)\n    \n    # --- Confusion matrix (test set) ---\n    cm = confusion_matrix(y_test, y_test_pred)\n    plt.figure(figsize=(5,4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n    plt.title(f\"{name} - Confusion Matrix (Test Set)\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()\n    \n    # --- Print metrics ---\n    print(f\"\\n===== {name} =====\")\n    print(f\"Training Accuracy : {train_acc:.3f} | ROC-AUC : {train_auc:.3f}\")\n    print(f\"Test Accuracy     : {test_acc:.3f} | ROC-AUC : {test_auc:.3f}\")\n    print(f\"Cross-Validation Accuracy : {cv_scores['test_accuracy'].mean():.3f} Â± {cv_scores['test_accuracy'].std():.3f}\")\n    print(f\"Cross-Validation ROC-AUC  : {cv_scores['test_roc_auc'].mean():.3f} Â± {cv_scores['test_roc_auc'].std():.3f}\")\n    print(classification_report(y_test, y_test_pred))\n    \n    # --- Save results ---\n    results[name] = {\n        \"train_accuracy\": train_acc,\n        \"train_roc_auc\": train_auc,\n        \"test_accuracy\": test_acc,\n        \"test_roc_auc\": test_auc,\n        \"cv_accuracy_mean\": cv_scores['test_accuracy'].mean(),\n        \"cv_accuracy_std\": cv_scores['test_accuracy'].std(),\n        \"cv_roc_auc_mean\": cv_scores['test_roc_auc'].mean(),\n        \"cv_roc_auc_std\": cv_scores['test_roc_auc'].std(),\n        \"confusion_matrix\": cm\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:21:20.984905Z","iopub.execute_input":"2025-08-28T21:21:20.985167Z","iopub.status.idle":"2025-08-28T21:22:02.330718Z","shell.execute_reply.started":"2025-08-28T21:21:20.985122Z","shell.execute_reply":"2025-08-28T21:22:02.329463Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**","metadata":{}},{"cell_type":"markdown","source":"**According to the above results Logistic Regression is the best model so far**","metadata":{}},{"cell_type":"markdown","source":"# **Hyperparameter tuning**","metadata":{}},{"cell_type":"code","source":"# Pipeline: preprocessing + model\nclf_new = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"classifier\", LogisticRegression(max_iter=1000))\n])\n\n# Hyperparameter grid\nparam_grid = {\n    'classifier__C': [0.01, 0.1, 1, 10, 100],\n    'classifier__penalty': ['l2'],\n    'classifier__solver': ['lbfgs']\n}\n\n# Stratified CV\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# GridSearchCV\ngrid_search = GridSearchCV(\n    clf_new, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1\n)\n\n# Fit\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best CV ROC-AUC:\", grid_search.best_score_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:22:02.332251Z","iopub.execute_input":"2025-08-28T21:22:02.332606Z","iopub.status.idle":"2025-08-28T21:22:06.941384Z","shell.execute_reply.started":"2025-08-28T21:22:02.332576Z","shell.execute_reply":"2025-08-28T21:22:06.940096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_model = grid_search.best_estimator_\nfinal_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:22:06.943241Z","iopub.execute_input":"2025-08-28T21:22:06.944278Z","iopub.status.idle":"2025-08-28T21:22:07.092504Z","shell.execute_reply.started":"2025-08-28T21:22:06.944246Z","shell.execute_reply":"2025-08-28T21:22:07.090651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Fit on full training set ---\nfinal_model.fit(X_train, y_train)\n\n# --- Predictions for training and test sets ---\ny_train_pred = final_model.predict(X_train)\ny_test_pred = final_model.predict(X_test)\n\ny_train_proba = final_model.predict_proba(X_train)[:,1]\ny_test_proba = final_model.predict_proba(X_test)[:,1]\n\n# --- Metrics ---\ntrain_acc = accuracy_score(y_train, y_train_pred)\ntest_acc = accuracy_score(y_test, y_test_pred)\ntrain_auc = roc_auc_score(y_train, y_train_proba)\ntest_auc = roc_auc_score(y_test, y_test_proba)\n\n# --- Confusion matrix (test set) ---\ncm = confusion_matrix(y_test, y_test_pred)\nplt.figure(figsize=(5,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\nplt.title(\"Logistic regression after hyperparameter tunning Confusion Matrix (Test Set)\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n# --- Print metrics ---\nprint(\"\\n===== Logistic regression after hyperparameter tunning=====\")\nprint(f\"Training Accuracy : {train_acc:.3f} | ROC-AUC : {train_auc:.3f}\")\nprint(f\"Test Accuracy     : {test_acc:.3f} | ROC-AUC : {test_auc:.3f}\")\nprint(f\"Cross-Validation Accuracy : {cv_scores['test_accuracy'].mean():.3f} Â± {cv_scores['test_accuracy'].std():.3f}\")\nprint(f\"Cross-Validation ROC-AUC  : {cv_scores['test_roc_auc'].mean():.3f} Â± {cv_scores['test_roc_auc'].std():.3f}\")\nprint(classification_report(y_test, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:22:07.094201Z","iopub.execute_input":"2025-08-28T21:22:07.094560Z","iopub.status.idle":"2025-08-28T21:22:08.433193Z","shell.execute_reply.started":"2025-08-28T21:22:07.094531Z","shell.execute_reply":"2025-08-28T21:22:08.432124Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Predictions**","metadata":{}},{"cell_type":"code","source":"# Predict for test data\ntest_preds = final_model.predict(X_test)\n\n# Add predicted churn\npredictions_df = X_test.copy()\npredictions_df[\"Predicted Churn\"] = test_preds\npredictions_df[\"customerID\"] = customer_id\n\n# Reorder columns: customerID first\ncols = [\"customerID\"] + [col for col in predictions_df.columns if col != \"customerID\"]\npredictions_df = predictions_df[cols]\n\n# View first few rows\npredictions_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T21:22:08.434409Z","iopub.execute_input":"2025-08-28T21:22:08.434719Z","iopub.status.idle":"2025-08-28T21:22:08.482943Z","shell.execute_reply.started":"2025-08-28T21:22:08.434697Z","shell.execute_reply":"2025-08-28T21:22:08.481934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Conclusion**","metadata":{}},{"cell_type":"markdown","source":"In this project, we developed a robust machine learning pipeline to predict customer churn for a telecom company using the Telco Customer Churn dataset. The workflow covered data preprocessing, feature engineering, model training, evaluation, and prediction, ensuring a reproducible and production-ready pipeline.\n\n**Key Steps and Insights**\n\n* Data Preprocessing\n* Handled numeric and categorical features separately.\n* Applied a square root transformation to reduce skewness in TotalCharges.\n* Standardized all numeric features using StandardScaler.\n* Encoded categorical features with OneHotEncoder, ignoring unknown categories.\n* Dropped irrelevant identifiers like customerID from the modeling features.\n* Feature-Target Split and Data Splitting\n* The target variable Churn was mapped to binary values (Yes=1, No=0).\n* Stratified train-test split ensured balanced representation of classes in both sets.\n* Modeling and Evaluation\n* Multiple classification models were tested: Logistic Regression, Decision Tree, Random Forest, XGBoost, and CatBoost.\n* Cross-validation was performed with stratification to obtain reliable performance estimates.\n* Metrics evaluated included accuracy, ROC-AUC, and confusion matrices to capture both overall and class-level performance.\n\n**Logistic Regression** emerged as the best-performing model of an 80% of test accuracy, achieving a high ROC-AUC and balanced accuracy, indicating both good predictive power and generalization.\n\n**Hyperparameter Tuning**\n\n* **GridSearchCV** was used to tune the regularization strength (C) of Logistic Regression.\n* The final model combined preprocessing and tuned Logistic Regression in a single pipeline, ensuring that test data can be predicted without additional preprocessing.\n\n**Predictions and Output**\n\n* Predicted probabilities for the positive class (churn) were generated on the test set.\n* A final DataFrame was created that retained all original features along with customerID and the predicted churn probability, ready for analysis or submission.\n\n**Key Takeaways**\n\n* Pipelines and ColumnTransformers ensure that preprocessing and modeling are fully reproducible and avoid data leakage.\n* Cross-validation and ROC-AUC are essential for evaluating models on imbalanced datasets like churn prediction.\n* Even simple models like Logistic Regression can perform strongly when proper preprocessing and hyperparameter tuning are applied.\n* Feature engineering (e.g., sqrt transform for skewed data) significantly improves model stability and performance.\n\n**Future Work / Improvements**\n\n* Explore feature interactions or derived features for better predictive performance.\n* Consider class imbalance handling using **SMOTE** if the churn ratio is highly skewed.\n* Deploy the pipeline as a predictive service for real-time churn probability estimation.\n\nConclusion: The project demonstrates a complete end-to-end machine learning workflow. Logistic Regression, combined with thoughtful preprocessing and hyperparameter tuning, provides an effective solution for predicting telecom customer churn with interpretable and reproducible results.\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
